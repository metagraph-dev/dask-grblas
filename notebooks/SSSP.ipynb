{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b68c64a",
   "metadata": {},
   "source": [
    "# SSSP Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import numpy as np\n",
    "import grblas as gb\n",
    "import dask_grblas as dgb\n",
    "from grblas import op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78366496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "N = 1000\n",
    "num_chunks = 4\n",
    "r = np.random.rand(N, N) < 0.001\n",
    "r = r | r.T  # symmetric\n",
    "r = r & ~np.diag(np.ones(N, dtype=bool))  # no self edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f90dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: create distributed Matrix from local data\n",
    "def to_matrix(chunk):\n",
    "    rows, cols = np.nonzero(chunk)\n",
    "    values = np.random.rand(rows.size)\n",
    "    return dgb.Matrix.from_values(\n",
    "        rows,\n",
    "        cols,\n",
    "        values,\n",
    "        nrows=chunk.shape[0],\n",
    "        ncols=chunk.shape[1]\n",
    "    )\n",
    "chunks = np.array_split(r, num_chunks, axis=0)\n",
    "delayed_chunks = [to_matrix(chunk) for chunk in chunks]\n",
    "A = dgb.row_stack(delayed_chunks)\n",
    "sources = dgb.Vector.from_values(\n",
    "    np.random.randint(N),\n",
    "    0,\n",
    "    size=N,\n",
    "    dtype=A.dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: create distributed Matrix from distributed (delayed) data\n",
    "chunks = np.array_split(r, num_chunks, axis=0)\n",
    "ncols = chunks[0].shape[1]\n",
    "row_lengths = np.array([chunk.shape[0] for chunk in chunks])\n",
    "row_offsets = np.roll(row_lengths.cumsum(), 1)\n",
    "row_offsets[0] = 0\n",
    "\n",
    "chunked_rows = []\n",
    "chunked_cols = []\n",
    "chunked_vals = []\n",
    "for chunk, row_offset in zip(chunks, row_offsets):\n",
    "    rows, cols = np.nonzero(chunk)\n",
    "    chunked_rows.append(rows + row_offset)\n",
    "    chunked_cols.append(cols)\n",
    "    chunked_vals.append(np.random.rand(rows.size))\n",
    "\n",
    "delayed_rows = [dask.delayed(rows) for rows in chunked_rows]\n",
    "delayed_cols = [dask.delayed(cols) for cols in chunked_cols]\n",
    "delayed_vals = [dask.delayed(cols) for cols in chunked_vals]\n",
    "\n",
    "@dask.delayed\n",
    "def to_matrix(rows, cols, vals, nrows, ncols):\n",
    "    # Can also use e.g. gb.Matrix.ss.import_csr\n",
    "    return gb.Matrix.from_values(rows, cols, vals, nrows=nrows, ncols=ncols)\n",
    "\n",
    "delayed_matrices = [\n",
    "    to_matrix(\n",
    "        delayed_rows[i] - row_offsets[i],\n",
    "        delayed_cols[i],\n",
    "        delayed_vals[i],\n",
    "        row_lengths[i],\n",
    "        ncols\n",
    "    ) for i in range(num_chunks)\n",
    "]\n",
    "\n",
    "delayed_chunks = [\n",
    "    dgb.Matrix.from_delayed(\n",
    "        delayed_matrices[i],\n",
    "        gb.dtypes.FP64,\n",
    "        row_lengths[i],\n",
    "        ncols,\n",
    "    )\n",
    "    for i in range(num_chunks)\n",
    "]\n",
    "\n",
    "A = dgb.row_stack(delayed_chunks)\n",
    "sources = dgb.Vector.from_values(\n",
    "    np.random.randint(N),\n",
    "    0,\n",
    "    size=N,\n",
    "    dtype=A.dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eec8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected with grblas\n",
    "B = A.compute()\n",
    "v = sources.dup().compute()\n",
    "v_dup = gb.Vector.new(v.dtype, size=N)\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    v_dup << v\n",
    "    v(op.min) << B.mxv(v, op.min_plus)\n",
    "    if v.isequal(v_dup):\n",
    "        break\n",
    "expected = v\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2648a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate with dask-grblas\n",
    "i = 0\n",
    "v = sources.dup()\n",
    "while True:\n",
    "    i += 1\n",
    "    v_dup = v.dup()\n",
    "    v(op.min) << A.mxv(v, op.min_plus)\n",
    "    # persist so we don't recompute every iteration\n",
    "    v._delayed = v._delayed.persist()  # scheduler='synchronous')\n",
    "    if v.isequal(v_dup):\n",
    "        break\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert expected.isequal(v.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd1c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
